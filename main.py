from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent
from google.adk.models.google_llm import Gemini
from google.adk.runners import InMemoryRunner
from google.adk.tools import AgentTool, FunctionTool, google_search
from google.genai import types
from dotenv import load_dotenv
import asyncio
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
import os

load_dotenv()

# Initialize embeddings and vector database (using free local HuggingFace embeddings)
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectordb = None

def load_pdf_to_vectordb(pdf_path: str):
    """Load PDF, split into chunks, embed and store in ChromaDB"""
    global vectordb
    
    # Load PDF
    loader = PyPDFLoader(pdf_path)
    documents = loader.load()
    
    # Split documents into chunks
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200
    )
    chunks = text_splitter.split_documents(documents)
    
    # Create or update vector database
    vectordb = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory="./chroma_db"
    )
    
    return f"Successfully loaded {len(chunks)} chunks from PDF into database"

def search_vectordb(query: str, k: int = 5) -> str:
    """Search the vector database for relevant content based on a query. Returns the most relevant text chunks from the loaded PDF documents."""
    if vectordb is None:
        return "Error: Vector database not initialized. Please load a PDF first."
    
    results = vectordb.similarity_search(query, k=k)
    
    if not results:
        return "No relevant content found in the database."
    
    # Format results
    formatted_results = []
    for i, doc in enumerate(results, 1):
        formatted_results.append(f"Result {i}:\n{doc.page_content}\n")
    
    return "\n".join(formatted_results)

# Create the database search tool
db_search_tool = FunctionTool(func=search_vectordb)

retry_config=types.HttpRetryOptions(
    attempts=5,  # Maximum retry attempts
    exp_base=7,  # Delay multiplier
    initial_delay=1,
    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors
)

content_sumarization_agent = Agent(
    name = "content_summarization_agent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""You are a content summarization agent. You can fetch data from the vector database using the search_vectordb tool and summarize it effectively. Use the tool to retrieve relevant information based on the user's query.""",
    tools = [db_search_tool],
    output_key="summary"
)

question_genrator_agent = Agent(
    name = "question_generation_agent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""You are a question generation agent that can generate relevant questions based on the summarized content provided by the Content Summarization Agent.""",
    tools = [],
    output_key="questions"
)

doubt_clarification_agent = Agent(
    name = "doubt_clarification_agent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""You are a doubt clarification agent that can clarify doubts based on the questions generated by the Question Generation Agent. and can even use google search to fetch more information if required.""",
    tools = [google_search],
    output_key="clarifications"
)

main_agent = SequentialAgent(
    name="main_agent",
    sub_agents=[content_sumarization_agent, question_genrator_agent, doubt_clarification_agent]
)

if __name__ == "__main__":
    async def main():
        # Load PDF into vector database
        pdf_path = "a.pdf"  # Change this to your PDF path
        
        if os.path.exists(pdf_path):
            print("Loading PDF into vector database...")
            result = load_pdf_to_vectordb(pdf_path)
            print(result)
            print("\nPDF loaded successfully! You can now ask questions about it.\n")
        else:
            print(f"Warning: PDF file '{pdf_path}' not found.")
            print("You can still ask general questions, but PDF search won't be available.\n")
        
        runner = InMemoryRunner(agent=main_agent)
        
        print("=" * 70)
        print("Interactive Chat - Ask questions about your document")
        print("Commands: 'exit' or 'quit' to stop, 'clear' to clear screen")
        print("=" * 70)
        print()
        
        # Continuous chat loop
        while True:
            try:
                # Get user input
                user_query = input("You: ").strip()
                
                # Check for exit commands
                if user_query.lower() in ['exit', 'quit', 'q']:
                    print("\nGoodbye!")
                    break
                
                # Clear screen command
                if user_query.lower() == 'clear':
                    os.system('cls' if os.name == 'nt' else 'clear')
                    continue
                
                # Skip empty queries
                if not user_query:
                    continue
                
                print("\nAssistant: ", end="", flush=True)
                
                # Run the agent with user query
                events = await runner.run_debug(user_messages=user_query, quiet=True)
                
                # Print only the final response
                for event in events:
                    if hasattr(event, 'content') and event.content:
                        # Extract text from content
                        if hasattr(event.content, 'parts'):
                            for part in event.content.parts:
                                if hasattr(part, 'text') and part.text:
                                    print(part.text)
                
                print()  # Add newline after response
                
            except KeyboardInterrupt:
                print("\n\nGoodbye!")
                break
            except Exception as e:
                print(f"\nError: {e}")
                print("Please try again.\n")
    
    asyncio.run(main())